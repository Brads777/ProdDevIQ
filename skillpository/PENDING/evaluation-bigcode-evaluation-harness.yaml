# Discovered by skillpository-manager scan
name: "evaluation-bigcode-evaluation-harness"
type: skill
source_repo: "davila7/claude-code-templates"
source_path: "cli-tool/components/skills/ai-research/evaluation-bigcode-evaluation-harness/SKILL.md"
source_url: "https://github.com/davila7/claude-code-templates/tree/main/cli-tool/components/skills/ai-research/evaluation-bigcode-evaluation-harness"
description: "Evaluates code generation models across HumanEval, MBPP, MultiPL-E, and 15+ benchmarks with pass@k metrics. Use when benchmarking code models, comparing coding abilities, testing multi-language support, or measuring code generation quality. Industry standard from BigCode Project used by HuggingFace leaderboards."
discovered: "2026-02-07 22:29"
label: "davila7 Templates"
status: pending
